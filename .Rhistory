hist(freq$n)
summary(freq)
# Filtramos combinaciones categoría-presentación poco frecuentes
freq <- data[Fecha == min(Fecha),.(precio = mean(precio, na.rm=T)), by=.(producto_id,presentacion,idCategoria)] %>%
.[n >= 10,.(n = .N), by=.(idCategoria,presentacion)]
# Filtramos combinaciones categoría-presentación poco frecuentes
freq <- data[Fecha == min(Fecha),.(precio = mean(precio, na.rm=T)), by=.(producto_id,presentacion,idCategoria)] %>%
.[,.(n = .N), by=.(idCategoria,presentacion)][n >= 10]
# Filtramos combinaciones categoría-presentación poco frecuentes
freq <- data[Fecha == min(Fecha),.(precio = mean(precio, na.rm=T)), by=.(producto_id,presentacion,idCategoria)] %>%
.[,.(n = .N), by=.(idCategoria,presentacion)] %>%
.[n >= 10]
head(freq)
hist(freq$n)
# Filtramos combinaciones categoría-presentación poco frecuentes
print(length(unique(data$idCategoria)))
print(length(unique(freq$idCategoria)))
freq <- data[Fecha == min(Fecha),.(precio = mean(precio, na.rm=T)), by=.(producto_id,presentacion,idCategoria)] %>%
.[,.(n = .N), by=.(idCategoria,presentacion)] %>%
.[n >= 5]
print(length(unique(freq$idCategoria)))
# Creamos indicador "high-end" y lo incorporamos al dataset
high_end <- data[Fecha == min(Fecha), .(precio = mean(precio, na.rm = T)), by = .(producto_id,presentacion,idCategoria)] %>%
.[, high_end := ifelse(precio > median(precio, na.rm = T),TRUE,FALSE), by = 'idCategoria'] %>%
.[,!c('idCategoria','precio')]
data <- merge.data.table(data, high_end, all.x = TRUE, by = 'producto_id')
# Calculamos la variación intersemanal de precios por producto, por comercio
setorder(data,id_comercio,producto_id,Fecha)
data <- data[,chg := (precio/shift(precio, n=1L)-1)*100][Fecha > as.Date("2020-01-12")]
# Importamos precios cuidados
load("/home/julian/Documents/GitHub/Tesis_Grado/input_data/preciosCuidados_listado_07-01-2020.RData")
preciosCuidados <- preciosCuidados %>% filter(nchar(as.character(amba)) > 0)
data$PC <- ifelse(data$producto_id %in% preciosCuidados$ean,1,0)
data <- data[,D := sum(PC),by = idCategoria][D > 0, D := 1]
# Eliminamos outliers
chg <- data$chg
outliers <- boxplot.stats(chg[chg != 0])$out
outliers <- c(max(outliers[outliers < 0]),min(outliers[outliers > 0]))
outliers <- data %>% filter(chg < outliers[1] | chg > outliers[2]) %>% select(producto_id,id_comercio) %>% distinct() %>% mutate(outlier = TRUE)
print(length(unique(data$producto_id)))
data <- data %>% left_join(outliers, by = c('producto_id','id_comercio')) %>% filter(is.na(outlier)) %>% select(-outlier)
print(length(unique(data$producto_id)))
comercios_amba <- readRDS('/home/julian/Documents/GitHub/Tesis_Grado/comercios_amba.RDS')
datareg <- data %>%
filter(id_comercio %in% comercios_amba) %>%
mutate(a1 = ifelse(D == 1 & high_end == 0,1,0),
a2 = D*high_end,
b1 = ifelse(D == 0 & high_end == 0,1,0),
b2 = ifelse(D == 0 & high_end == 1,1,0))
model <- felm(formula = chg ~ chg ~ a2 + b1 + b2 | broad_category + cadena + Fecha,
data = datareg)
#coeftest(model, vcov = vcovHC(model, 'HC0'))
summary(model)
freq <- data[Fecha == min(Fecha),.(precio = mean(precio, na.rm=T)), by=.(producto_id,presentacion,idCategoria)] %>%
.[,.(n = .N), by=.(idCategoria,presentacion)] %>%
.[n >= 10]
rm(list = ls())
if(!require('pacman')) install.packages('pacman')
pacman::p_load(tidyverse,data.table,lfe,sandwich,lmtest)
data <- readRDS('/home/julian/Desktop/seriePrecios_12052020.RDS')
data <- as.data.table(data)
# Nos quedamos con las fechas que nos interesan
data <- data[Fecha >= as.Date('2020-01-07') & Fecha < as.Date('2020-03-06')]
# Nos aseguramos que el producto aparezca en el comercio para todas las fechas
data <- data[,n := .N, by = .(id_comercio,producto_id)][n == 8][,n := NULL]
# Cargamos categorías
load('/home/julian/Documents/GitHub/Tesis_Grado/productosCategoriaYCategorias.RData')
rm(categorias)
productosCategoria$idCategoria <- substr(productosCategoria$idCategoria,1,6)
productosCategoria <- productosCategoria %>% filter(nchar(idCategoria) == 6)
# Matcheamos categorías con las observaciones
productosCategoria <- productosCategoria %>% select(id,presentacion,idCategoria) %>% rename(producto_id = id) %>% distinct()
data <- merge.data.table(data, productosCategoria, all.x = TRUE, by = 'producto_id') %>% .[!is.na(idCategoria) & !is.na(presentacion)]
data <- data[, broad_category := substr(idCategoria,1,4)]
# Agregamos identificador de cadena
data <- data[,cadena := unlist(lapply(strsplit(id_comercio,'-'), function(x) paste0(x[1],'-',x[2])))]
head(data)
# Filtramos combinaciones categoría-presentación poco frecuentes
print(length(unique(data$idCategoria)))
freq <- data[Fecha == min(Fecha),.(precio = mean(precio, na.rm=T)), by=.(producto_id,presentacion,idCategoria)] %>%
.[,.(n = .N), by=.(idCategoria,presentacion)] %>%
.[n >= 5]
print(length(unique(freq$idCategoria)))
data <- data[idCategoria %in% freq$idCategoria]
# Creamos indicador "high-end" y lo incorporamos al dataset
high_end <- data[Fecha == min(Fecha), .(precio = mean(precio, na.rm = T)), by = .(producto_id,presentacion,idCategoria)] %>%
.[, high_end := ifelse(precio > median(precio, na.rm = T),TRUE,FALSE), by = 'idCategoria'] %>%
.[,!c('idCategoria','precio')]
data <- merge.data.table(data, high_end, all.x = TRUE, by = 'producto_id')
# Calculamos la variación intersemanal de precios por producto, por comercio
setorder(data,id_comercio,producto_id,Fecha)
data <- data[,chg := (precio/shift(precio, n=1L)-1)*100][Fecha > as.Date("2020-01-12")]
# Importamos precios cuidados
load("/home/julian/Documents/GitHub/Tesis_Grado/input_data/preciosCuidados_listado_07-01-2020.RData")
preciosCuidados <- preciosCuidados %>% filter(nchar(as.character(amba)) > 0)
data$PC <- ifelse(data$producto_id %in% preciosCuidados$ean,1,0)
data <- data[,D := sum(PC),by = idCategoria][D > 0, D := 1]
# Eliminamos outliers
chg <- data$chg
outliers <- boxplot.stats(chg[chg != 0])$out
outliers <- c(max(outliers[outliers < 0]),min(outliers[outliers > 0]))
outliers <- data %>% filter(chg < outliers[1] | chg > outliers[2]) %>% select(producto_id,id_comercio) %>% distinct() %>% mutate(outlier = TRUE)
print(length(unique(data$producto_id)))
data <- data %>% left_join(outliers, by = c('producto_id','id_comercio')) %>% filter(is.na(outlier)) %>% select(-outlier)
print(length(unique(data$producto_id)))
comercios_amba <- readRDS('/home/julian/Documents/GitHub/Tesis_Grado/comercios_amba.RDS')
datareg <- data %>%
filter(id_comercio %in% comercios_amba) %>%
mutate(a1 = ifelse(D == 1 & high_end == 0,1,0),
a2 = D*high_end,
b1 = ifelse(D == 0 & high_end == 0,1,0),
b2 = ifelse(D == 0 & high_end == 1,1,0))
model <- felm(formula = chg ~ chg ~ a2 + b1 + b2 | broad_category + cadena + Fecha,
data = datareg)
#coeftest(model, vcov = vcovHC(model, 'HC0'))
summary(model)
freq <- data[Fecha == min(Fecha),.(precio = mean(precio, na.rm=T)), by=.(producto_id,presentacion,idCategoria)] %>%
.[,.(n = .N), by=.(idCategoria,presentacion)] %>%
.[n >= 10]
rm(list = ls())
gc()
if(!require('pacman')) install.packages('pacman')
pacman::p_load(tidyverse,data.table,lfe,sandwich,lmtest)
data <- readRDS('/home/julian/Desktop/seriePrecios_12052020.RDS')
data <- as.data.table(data)
# Nos quedamos con las fechas que nos interesan
data <- data[Fecha >= as.Date('2020-01-07') & Fecha < as.Date('2020-03-06')]
# Nos aseguramos que el producto aparezca en el comercio para todas las fechas
data <- data[,n := .N, by = .(id_comercio,producto_id)][n == 8][,n := NULL]
# Cargamos categorías
load('/home/julian/Documents/GitHub/Tesis_Grado/productosCategoriaYCategorias.RData')
rm(categorias)
productosCategoria$idCategoria <- substr(productosCategoria$idCategoria,1,6)
productosCategoria <- productosCategoria %>% filter(nchar(idCategoria) == 6)
# Matcheamos categorías con las observaciones
productosCategoria <- productosCategoria %>% select(id,presentacion,idCategoria) %>% rename(producto_id = id) %>% distinct()
data <- merge.data.table(data, productosCategoria, all.x = TRUE, by = 'producto_id') %>% .[!is.na(idCategoria) & !is.na(presentacion)]
data <- data[, broad_category := substr(idCategoria,1,4)]
# Agregamos identificador de cadena
data <- data[,cadena := unlist(lapply(strsplit(id_comercio,'-'), function(x) paste0(x[1],'-',x[2])))]
# Filtramos combinaciones categoría-presentación poco frecuentes
print(length(unique(data$idCategoria)))
freq <- data[Fecha == min(Fecha),.(precio = mean(precio, na.rm=T)), by=.(producto_id,presentacion,idCategoria)] %>%
.[,.(n = .N), by=.(idCategoria,presentacion)] %>%
.[n >= 10]
print(length(unique(freq$idCategoria)))
data <- data[idCategoria %in% freq$idCategoria]
# Creamos indicador "high-end" y lo incorporamos al dataset
high_end <- data[Fecha == min(Fecha), .(precio = mean(precio, na.rm = T)), by = .(producto_id,presentacion,idCategoria)] %>%
.[, high_end := ifelse(precio > median(precio, na.rm = T),TRUE,FALSE), by = 'idCategoria'] %>%
.[,!c('idCategoria','precio')]
data <- merge.data.table(data, high_end, all.x = TRUE, by = 'producto_id')
# Calculamos la variación intersemanal de precios por producto, por comercio
setorder(data,id_comercio,producto_id,Fecha)
data <- data[,chg := (precio/shift(precio, n=1L)-1)*100][Fecha > as.Date("2020-01-12")]
# Importamos precios cuidados
load("/home/julian/Documents/GitHub/Tesis_Grado/input_data/preciosCuidados_listado_07-01-2020.RData")
preciosCuidados <- preciosCuidados %>% filter(nchar(as.character(amba)) > 0)
data$PC <- ifelse(data$producto_id %in% preciosCuidados$ean,1,0)
data <- data[,D := sum(PC),by = idCategoria][D > 0, D := 1]
# Eliminamos outliers
chg <- data$chg
outliers <- boxplot.stats(chg[chg != 0])$out
outliers <- c(max(outliers[outliers < 0]),min(outliers[outliers > 0]))
outliers <- data %>% filter(chg < outliers[1] | chg > outliers[2]) %>% select(producto_id,id_comercio) %>% distinct() %>% mutate(outlier = TRUE)
print(length(unique(data$producto_id)))
data <- data %>% left_join(outliers, by = c('producto_id','id_comercio')) %>% filter(is.na(outlier)) %>% select(-outlier)
print(length(unique(data$producto_id)))
comercios_amba <- readRDS('/home/julian/Documents/GitHub/Tesis_Grado/comercios_amba.RDS')
datareg <- data %>%
filter(id_comercio %in% comercios_amba) %>%
mutate(a1 = ifelse(D == 1 & high_end == 0,1,0),
a2 = D*high_end,
b1 = ifelse(D == 0 & high_end == 0,1,0),
b2 = ifelse(D == 0 & high_end == 1,1,0))
model <- felm(formula = chg ~ chg ~ a2 + b1 + b2 | broad_category + cadena + Fecha,
data = datareg)
#coeftest(model, vcov = vcovHC(model, 'HC0'))
summary(model)
head(data[idCategoria == '020102'])
head(Data)
head(data)
head(data[idCategoria == '020102',])
head(data %>% filter(idCategoria == '020102'))
ggplot(data = data %>% filter(Fecha == min(Fecha), idCategoria == '020102', presentacion.x == '1.5 lt'),
aes(x = log(precio), fill = high_end, alpha = 0.8)) +
theme_bw()
ggplot(data = data %>% filter(Fecha == min(Fecha), idCategoria == '020102', presentacion.x == '1.5 lt'),
aes(x = precio, fill = high_end, alpha = 0.8)) +
theme_bw()
data %>% filter(Fecha == min(Fecha), idCategoria == '020102', presentacion.x == '1.5 lt')
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020102', presentacion.x == '1.5 lt') %>%
group_by(producto_id) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
theme_bw()
data %>%
filter(Fecha == min(Fecha), idCategoria == '020102', presentacion.x == '1.5 lt') %>%
group_by(producto_id) %>%
summarize(precio = mean(precio, na.rm = T))
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020102', presentacion.x == '1.5 lt') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
theme_bw()
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020102', presentacion.x == '1.5 lt') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
head(data %>%
filter(Fecha == min(Fecha), idCategoria == '020102'),20)
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020102', presentacion.x == '900.0 ml') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020102', presentacion.x == '900.0 cc') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
head(data %>%
filter(Fecha == min(Fecha), idCategoria == '020102'),20)
head(data %>%
filter(Fecha == min(Fecha), idCategoria == '020902'),20)
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020902', presentacion.x == '500.0 gr') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020902', presentacion.x == '500.0 gr') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, y = ..scaled.., fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020902', presentacion.x == '500.0 gr') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020902') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020102') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020103') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020104') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
ggplot(data = data %>%
filter(Fecha == min(Fecha), idCategoria == '020104') %>%
group_by(producto_id, high_end) %>%
summarize(precio = mean(precio, na.rm = T)),
aes(x = precio, y = ..scaled.., fill = high_end, alpha = 0.8)) +
geom_density() +
theme_bw()
rm(list = ls())
if(!require('pacman')) install.packages('pacman')
pacman::p_load(tidyverse,data.table,lfe,sandwich,lmtest)
data <- readRDS('/home/julian/Desktop/seriePrecios_12052020.RDS')
data <- as.data.table(data)
# Nos quedamos con las fechas que nos interesan
data <- data[Fecha >= as.Date('2020-01-07') & Fecha < as.Date('2020-03-06')]
# Nos aseguramos que el producto aparezca en el comercio para todas las fechas
data <- data[,n := .N, by = .(id_comercio,producto_id)][n == 8][,n := NULL]
# Cargamos categorías
load('/home/julian/Documents/GitHub/Tesis_Grado/productosCategoriaYCategorias.RData')
rm(categorias)
productosCategoria$idCategoria <- substr(productosCategoria$idCategoria,1,6)
productosCategoria <- productosCategoria %>% filter(nchar(idCategoria) == 6)
# Matcheamos categorías con las observaciones
productosCategoria <- productosCategoria %>% select(id,presentacion,idCategoria) %>% rename(producto_id = id) %>% distinct()
data <- merge.data.table(data, productosCategoria, all.x = TRUE, by = 'producto_id') %>% .[!is.na(idCategoria) & !is.na(presentacion)]
data <- data[, broad_category := substr(idCategoria,1,4)]
# Agregamos identificador de cadena
data <- data[,cadena := unlist(lapply(strsplit(id_comercio,'-'), function(x) paste0(x[1],'-',x[2])))]
# Filtramos combinaciones categoría-presentación poco frecuentes
print(length(unique(data$idCategoria)))
freq <- data[Fecha == min(Fecha),.(precio = mean(precio, na.rm=T)), by=.(producto_id,presentacion,idCategoria)] %>%
.[,.(n = .N), by=.(idCategoria,presentacion)] %>%
.[n >= 20]
print(length(unique(freq$idCategoria)))
data <- data[idCategoria %in% freq$idCategoria]
# Creamos indicador "high-end" y lo incorporamos al dataset
high_end <- data[Fecha == min(Fecha), .(precio = mean(precio, na.rm = T)), by = .(producto_id,presentacion,idCategoria)] %>%
.[, high_end := ifelse(precio > median(precio, na.rm = T),TRUE,FALSE), by = 'idCategoria'] %>%
.[,!c('idCategoria','precio')]
data <- merge.data.table(data, high_end, all.x = TRUE, by = 'producto_id')
# Calculamos la variación intersemanal de precios por producto, por comercio
setorder(data,id_comercio,producto_id,Fecha)
data <- data[,chg := (precio/shift(precio, n=1L)-1)*100][Fecha > as.Date("2020-01-12")]
# Importamos precios cuidados
load("/home/julian/Documents/GitHub/Tesis_Grado/input_data/preciosCuidados_listado_07-01-2020.RData")
preciosCuidados <- preciosCuidados %>% filter(nchar(as.character(amba)) > 0)
data$PC <- ifelse(data$producto_id %in% preciosCuidados$ean,1,0)
data <- data[,D := sum(PC),by = idCategoria][D > 0, D := 1]
# Eliminamos outliers
chg <- data$chg
outliers <- boxplot.stats(chg[chg != 0])$out
outliers <- c(max(outliers[outliers < 0]),min(outliers[outliers > 0]))
outliers <- data %>% filter(chg < outliers[1] | chg > outliers[2]) %>% select(producto_id,id_comercio) %>% distinct() %>% mutate(outlier = TRUE)
print(length(unique(data$producto_id)))
data <- data %>% left_join(outliers, by = c('producto_id','id_comercio')) %>% filter(is.na(outlier)) %>% select(-outlier)
print(length(unique(data$producto_id)))
comercios_amba <- readRDS('/home/julian/Documents/GitHub/Tesis_Grado/comercios_amba.RDS')
datareg <- data %>%
filter(id_comercio %in% comercios_amba) %>%
mutate(a1 = ifelse(D == 1 & high_end == 0,1,0),
a2 = D*high_end,
b1 = ifelse(D == 0 & high_end == 0,1,0),
b2 = ifelse(D == 0 & high_end == 1,1,0))
model <- felm(formula = chg ~ chg ~ a2 + b1 + b2 | broad_category + cadena + Fecha,
data = datareg)
#coeftest(model, vcov = vcovHC(model, 'HC0'))
summary(model)
data <- readRDS('/home/julian/Desktop/data_tesis.RDS')
object.size(data)
923398568/1024
901756/1024
rm(list=ls())
# Cargamos todas las librerías necesarias
# pacman las carga y, de no estar instaladas, previamente las instala
if (!require('pacman')) install.packages('pacman')
pacman::p_load(tidyverse,mlr,glmnet,ROCR,splines,rpart,randomForest,gbm,tictoc)
# Fijamos el working directory
#setwd('/Users/julianregatky/Documents/GitHub/client_churn_ML2020')
setwd('/home/julian/Documents/GitHub/client_churn_ML2020')
# Importamos el dataset
dataset <- read.table('train.csv', header = T, sep =',', dec = '.')
# Cargamos funciones propias
source('functions.R')
tic()
# Eliminamos ID
dataset <- dataset %>% select(-ID)
# Eliminamos features cuasi-constantes
dataset <- removeConstantFeatures(dataset,
perc = 0.01, # Fijamos threshold del 99%
dont.rm = 'TARGET')
# Unificamos features duplicados
del_col <- c(); dataset_full <- dataset %>% na.omit()
for(i in 1:(ncol(dataset_full)-1)) {
for(j in (i+1):ncol(dataset_full)) {
if(cor(dataset_full[,i],dataset_full[,j]) > 0.99) {
# identificamos columnas idénticas en el data.frame
del_col <- c(del_col,j)
}
}
}
dataset <- dataset[,setdiff(1:ncol(dataset),del_col)] # Eliminamos una de las duplicadas
ct <- 0
for(i in 1:ncol(dataset)) {
most_freq <- prop.table(table(dataset[,i])) %>% .[order(desc(.))] %>% .[1]
if(most_freq > 0.9) {
dataset[,i] <- as.character(dataset[,i]) == names(most_freq)
ct <- ct + 1
cat('\rVariables binarizadas:',ct)
}
}
# La variable 'nac' es la única que cuenta con datos faltantes (56 obs con NA)
# Esto representa sólo ~0.17% de las obs. Imputamos datos faltantes con el valor TRUE
# que es el reportado para la variable en ~97.8% de los casos.
sum(is.na(dataset$nac))/length(dataset$nac) # ~0.17%
sum(dataset$nac[!is.na(dataset$nac)] == TRUE)/sum(!is.na(dataset$nac)) # ~97.8%
dataset$nac[is.na(dataset$nac)] <- TRUE
set.seed(123) # Por replicabilidad
index_train <- sample(1:nrow(dataset),round(nrow(dataset)*0.8)) # Muestra de training
# Separamos en training, validation y testing sets (testing set idem antes)
test <- dataset[setdiff(1:nrow(dataset),index_train),]
index_validation <- sample(index_train,nrow(test)) # Separamos misma cant de obs que test set pero del training set para validación
train <- dataset[setdiff(index_train, index_validation),]
validation <- dataset[index_validation,]
full_grid <- expand.grid(mtry = 5:20, ntree = seq(500,3000,100), maxnodes = seq(20,100,5))
random_grid <- full_grid[sample(1:nrow(full_grid),30),]
i = 1
random.forest <- s(randomForest(factor(TARGET) ~.,
data = train,
mtry = sqrt(ncol(train)),
ntree = 2000,
maxnodes = 50,
importance = T,
proximity = F))
?randomForest
prop.table(table(train$TARGET == 1))
prop.table(table(train$TARGET == 1))[1]
random.forest <- s(randomForest(factor(TARGET) ~.,
data = train,
mtry = sqrt(ncol(train)),
ntree = 2000,
maxnodes = 50,
importance = T,
proximity = F,
cutoff = prop.table(table(train$TARGET == 1))[1]))
random.forest <- s(randomForest(factor(TARGET) ~.,
data = train,
mtry = sqrt(ncol(train)),
ntree = 2000,
maxnodes = 50,
importance = T,
proximity = F,
cutoff = prop.table(table(train$TARGET == 1))[2]))
prop.table(table(factor(train$TARGET)))
head(train$TARGET)
random.forest <- s(randomForest(factor(TARGET) ~.,
data = train,
mtry = sqrt(ncol(train)),
ntree = 2000,
maxnodes = 50,
importance = T,
proximity = F,
cutoff = prop.table(table(factor(train$TARGET)))))
pred.rforest = predict(random.forest,newdata=test)
performance(prediction(pred.rforest,factor(test$TARGET)),"auc")@y.values[[1]] #AUC
random.forest$predicted
random.forest$votes
pred.rforest = random.forest$votes[,2]
performance(prediction(pred.rforest,factor(train$TARGET)),"auc")@y.values[[1]] #AUC
random.forest <- s(randomForest(TARGET ~.,
data = train,
mtry = sqrt(ncol(train)),
ntree = 2000,
maxnodes = 50,
importance = T,
proximity = F))
table(random.forest$predicted,train$TARGET)
prop.table(table(random.forest$predicted,train$TARGET))
random.forest <- s(randomForest(TARGET ~.,
data = train,
mtry = ncol(train)/3,
ntree = 2000,
maxnodes = 50,
importance = T,
proximity = F))
random.forest$predicted
pred.rforest = random.forest$predicted
performance(prediction(pred.rforest,factor(train$TARGET)),"auc")@y.values[[1]] #AUC
# Separamos en training, validation y testing sets (testing set idem antes)
test <- dataset[setdiff(1:nrow(dataset),index_train),]
train <- dataset[index_train,]
full_grid <- expand.grid(mtry = 5:20, ntree = seq(500,3000,100), maxnodes = seq(20,100,5))
random_grid <- full_grid[sample(1:nrow(full_grid),30),]
best_auc <- 0
for(i in 1:nrow(random_grid)) {
random.forest <- s(randomForest(TARGET ~.,
data = train,
mtry = random_grid$mtry[i],
ntree = random_grid$ntree[i],
maxnodes = random_grid$maxnodes[i],
importance = T,
proximity = F))
pred.rforest = random.forest$predicted
cat(i,'|',paste(colnames(random_grid),random_grid[i,],collapse = ' - '),'| auc:',performance(prediction(pred.rforest,validation$TARGET),"auc")@y.values[[1]],'\n')
if(performance(prediction(pred.rforest,validation$TARGET),"auc")@y.values[[1]] > best_auc) {
best_model <- random.forest
best_auc <- performance(prediction(pred.rforest,validation$TARGET),"auc")@y.values[[1]]
}
}
full_grid <- expand.grid(mtry = 5:20, ntree = seq(500,3000,100), maxnodes = seq(20,100,5))
random_grid <- full_grid[sample(1:nrow(full_grid),30),]
best_auc <- 0
for(i in 1:nrow(random_grid)) {
random.forest <- s(randomForest(TARGET ~.,
data = train,
mtry = random_grid$mtry[i],
ntree = random_grid$ntree[i],
maxnodes = random_grid$maxnodes[i],
importance = T,
proximity = F))
pred.rforest = random.forest$predicted
cat(i,'|',paste(colnames(random_grid),random_grid[i,],collapse = ' - '),'| auc:',performance(prediction(pred.rforest,train$TARGET),"auc")@y.values[[1]],'\n')
if(performance(prediction(pred.rforest,train$TARGET),"auc")@y.values[[1]] > best_auc) {
best_model <- random.forest
best_auc <- performance(prediction(pred.rforest,train$TARGET),"auc")@y.values[[1]]
}
}
pred.rforest = predict(best_model,newdata=test)
# AUC
performance(prediction(pred.rforest,factor(test$TARGET)),"auc")@y.values[[1]] #AUC
auc_rforest <- performance(prediction(pred.rforest,test$TARGET),"tpr","fpr")
